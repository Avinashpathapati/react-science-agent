{"ray": {"sid": "54ab94af32e04fb8bfd8b61d08362ed0", "uid": null, "qid": "10205a3857d649c58c8f3e0218693c58", "rid": null, "bars": {"default": {"percent": "100", "remaining": "0"}}, "messages": [{"type": "ERROR", "content": "process - failed executing: [10205a3857d649c58c8f3e0218693c58]\nTraceback (most recent call last):\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openfabric_pysdk\\app\\worker.py\", line 90, in process\n    output = execution_callback_function(data, ray, self.state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\Downloads\\openfabric-ai-software-engineer 2\\openfabric-ai-software-engineer\\main.py\", line 135, in execute\n    response = agent_executor.invoke({\"input\": text})\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 89, in invoke\n    return self(\n           ^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 312, in __call__\n    raise e\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 306, in __call__\n    self._call(inputs, run_manager=run_manager)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1312, in _call\n    next_step_output = self._take_next_step(\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1038, in _take_next_step\n    [\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1038, in <listcomp>\n    [\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1066, in _iter_next_step\n    output = self.agent.plan(\n             ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 635, in plan\n    full_output = self.llm_chain.predict(callbacks=callbacks, **full_inputs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 293, in predict\n    return self(kwargs, callbacks=callbacks)[self.output_key]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 312, in __call__\n    raise e\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 306, in __call__\n    self._call(inputs, run_manager=run_manager)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 103, in _call\n    response = self.generate([inputs], run_manager=run_manager)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 115, in generate\n    return self.llm.generate_prompt(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 516, in generate_prompt\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 666, in generate\n    output = self._generate_helper(\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 553, in _generate_helper\n    raise e\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 540, in _generate_helper\n    self._generate(\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 1069, in _generate\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\llms\\huggingface_hub.py\", line 113, in _call\n    raise ValueError(f\"Error raised by inference API: {response['error']}\")\nValueError: Error raised by inference API: Model google/flan-t5-xl time out\n", "created_at": "2023-12-30T12:55:35.055247"}], "status": "FAILED", "created_at": "2023-12-30T12:54:44.240631", "updated_at": "2023-12-30T12:55:35.066080", "finished": true}, "in": {"text": ["string"]}, "out": {}}