{"ray": {"sid": "7d1a5833939d493187fd4cb1a09026a7", "uid": null, "qid": "2646e547aee74c9f93e8ecc7cb83ebd1", "rid": null, "bars": {"default": {"percent": "100", "remaining": "0"}}, "messages": [{"type": "ERROR", "content": "process - failed executing: [2646e547aee74c9f93e8ecc7cb83ebd1]\nTraceback (most recent call last):\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openfabric_pysdk\\app\\worker.py\", line 90, in process\n    output = execution_callback_function(data, ray, self.state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\Downloads\\openfabric-ai-software-engineer 2\\openfabric-ai-software-engineer\\main.py\", line 153, in execute\n    response = state.__dict__['agent_exec'].run({\"input\": text})\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 507, in run\n    return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 312, in __call__\n    raise e\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 306, in __call__\n    self._call(inputs, run_manager=run_manager)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1312, in _call\n    next_step_output = self._take_next_step(\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1038, in _take_next_step\n    [\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1038, in <listcomp>\n    [\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1066, in _iter_next_step\n    output = self.agent.plan(\n             ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 635, in plan\n    full_output = self.llm_chain.predict(callbacks=callbacks, **full_inputs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 293, in predict\n    return self(kwargs, callbacks=callbacks)[self.output_key]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 312, in __call__\n    raise e\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 306, in __call__\n    self._call(inputs, run_manager=run_manager)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 103, in _call\n    response = self.generate([inputs], run_manager=run_manager)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 112, in generate\n    prompts, stop = self.prep_prompts(input_list, run_manager=run_manager)\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 174, in prep_prompts\n    prompt = self.prompt.format_prompt(**selected_inputs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\prompts\\chat.py\", line 365, in format_prompt\n    messages = self.format_messages(**kwargs)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\prompts\\chat.py\", line 614, in format_messages\n    message = message_template.format_messages(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\prompts\\chat.py\", line 117, in format_messages\n    raise ValueError(\nValueError: variable chat_history should be a list of base messages, got \n", "created_at": "2023-12-31T09:40:07.283749"}], "status": "FAILED", "created_at": "2023-12-31T09:40:05.943180", "updated_at": "2023-12-31T09:40:07.283749", "finished": true}, "in": {"text": ["Tell me about Latvia"]}, "out": {}}