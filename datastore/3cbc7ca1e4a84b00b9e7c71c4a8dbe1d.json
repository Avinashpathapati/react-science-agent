{"ray": {"sid": "4a4fd61bcc7e4bd9b5e006c7cb1095ed", "uid": null, "qid": "3cbc7ca1e4a84b00b9e7c71c4a8dbe1d", "rid": null, "bars": {"default": {"percent": "100", "remaining": "0"}}, "messages": [{"type": "ERROR", "content": "process - failed executing: [3cbc7ca1e4a84b00b9e7c71c4a8dbe1d]\nTraceback (most recent call last):\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 261, in hf_raise_for_status\n    response.raise_for_status()\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/api/models/meta-llama/Llama-2-7b\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openfabric_pysdk\\app\\worker.py\", line 90, in process\n    output = execution_callback_function(data, ray, self.state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\Downloads\\openfabric-ai-software-engineer 2\\openfabric-ai-software-engineer\\main.py\", line 124, in execute\n    agent_executor = get_model_state()\n                     ^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\Downloads\\openfabric-ai-software-engineer 2\\openfabric-ai-software-engineer\\main.py\", line 51, in get_model_state\n    llm = HuggingFaceHub(\n          ^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\load\\serializable.py\", line 107, in __init__\n    super().__init__(**kwargs)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pydantic\\v1\\main.py\", line 339, in __init__\n    values, fields_set, validation_error = validate_model(__pydantic_self__.__class__, data)\n                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pydantic\\v1\\main.py\", line 1102, in validate_model\n    values = validator(cls_, values)\n             ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\llms\\huggingface_hub.py\", line 56, in validate_environment\n    client = InferenceApi(\n             ^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\utils\\_deprecation.py\", line 128, in inner_f\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\inference_api.py\", line 131, in __init__\n    model_info = HfApi(token=token).model_info(repo_id=repo_id)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py\", line 118, in _inner_fn\n    return fn(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\hf_api.py\", line 1698, in model_info\n    hf_raise_for_status(r)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\utils\\_errors.py\", line 277, in hf_raise_for_status\n    raise GatedRepoError(message, response) from e\nhuggingface_hub.utils._errors.GatedRepoError: 403 Client Error. (Request ID: Root=1-658ff8b4-39481171049a4149687b42e8;6543bfcd-3be1-4108-b6d6-a8337647cdc9)\n\nCannot access gated repo for url https://huggingface.co/api/models/meta-llama/Llama-2-7b.\nAccess to model meta-llama/Llama-2-7b is restricted and you are not in the authorized list. Visit https://huggingface.co/meta-llama/Llama-2-7b to ask for access.\n", "created_at": "2023-12-30T11:02:13.938659"}], "status": "FAILED", "created_at": "2023-12-30T11:02:12.569700", "updated_at": "2023-12-30T11:02:13.938659", "finished": true}, "in": {"text": ["what is poincare"]}, "out": {}}