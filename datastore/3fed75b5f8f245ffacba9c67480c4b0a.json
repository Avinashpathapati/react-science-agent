{"ray": {"sid": "820f110e2a8e4674968c63ff82f5c576", "uid": null, "qid": "3fed75b5f8f245ffacba9c67480c4b0a", "rid": null, "bars": {"default": {"percent": "100", "remaining": "0"}}, "messages": [{"type": "ERROR", "content": "process - failed executing: [3fed75b5f8f245ffacba9c67480c4b0a]\nTraceback (most recent call last):\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openfabric_pysdk\\app\\worker.py\", line 90, in process\n    output = execution_callback_function(data, ray, self.state)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\Downloads\\openfabric-ai-software-engineer 2\\openfabric-ai-software-engineer\\main.py\", line 228, in execute\n    response = agent_executor.run({\"input\": text})\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 507, in run\n    return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 312, in __call__\n    raise e\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 306, in __call__\n    self._call(inputs, run_manager=run_manager)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1312, in _call\n    next_step_output = self._take_next_step(\n                       ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1038, in _take_next_step\n    [\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1038, in <listcomp>\n    [\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 1066, in _iter_next_step\n    output = self.agent.plan(\n             ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\agents\\agent.py\", line 635, in plan\n    full_output = self.llm_chain.predict(callbacks=callbacks, **full_inputs)\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 293, in predict\n    return self(kwargs, callbacks=callbacks)[self.output_key]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 312, in __call__\n    raise e\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 306, in __call__\n    self._call(inputs, run_manager=run_manager)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 103, in _call\n    response = self.generate([inputs], run_manager=run_manager)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 115, in generate\n    return self.llm.generate_prompt(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 516, in generate_prompt\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 666, in generate\n    output = self._generate_helper(\n             ^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 553, in _generate_helper\n    raise e\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 540, in _generate_helper\n    self._generate(\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\llms.py\", line 1069, in _generate\n    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\n  File \"C:\\Users\\avina\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\llms\\huggingface_hub.py\", line 113, in _call\n    raise ValueError(f\"Error raised by inference API: {response['error']}\")\nValueError: Error raised by inference API: Input validation error: `inputs` must have less than 1024 tokens. Given: 1233\n", "created_at": "2023-12-30T15:06:52.157284"}], "status": "FAILED", "created_at": "2023-12-30T15:06:37.900542", "updated_at": "2023-12-30T15:06:52.158771", "finished": true}, "in": {"text": ["string"]}, "out": {}}